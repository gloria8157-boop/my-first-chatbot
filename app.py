import streamlit as st
import os
import json
import requests
import time
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# -------------------------------------------------------------
# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ë° Assistant ì„¤ì •
# -------------------------------------------------------------
deployment_name = "gpt-4o-mini" # ì±„íŒ… ëª¨ë¸ ì´ë¦„ (Assistantì™€ëŠ” ë³„ê°œë¡œ ì‚¬ìš©)
# Assistant APIëŠ” ëª¨ë¸ ë°°í¬ ì´ë¦„ì´ ì•„ë‹Œ ëª¨ë¸ ì´ë¦„(gpt-4o-mini)ì„ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.

client = AzureOpenAI(
    azure_endpoint = os.getenv("AZURE_OAI_ENDPOINT"),
    api_key= os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview" # Assistant APIëŠ” 2024-05-01-preview ë²„ì „ ì´ìƒì´ í•„ìš”
)

# Assistant IDì™€ Vector Store IDëŠ” í•œë²ˆ ìƒì„±ë˜ë©´ ë³€ê²½ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
# (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” IDë¥¼ í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê³  í™˜ê²½ ë³€ìˆ˜ ë“±ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.)
ASSISTANT_ID = os.getenv("AZURE_ASSISTANT_ID", "asst_placeholder_id") # ì‹¤ì œ Assistant IDë¡œ ëŒ€ì²´ í•„ìš”
VECTOR_STORE_ID = os.getenv("AZURE_VECTOR_STORE_ID", "vs_0HHlYCADIv0m8l3mWHLxbQp4")

# Streamlit ì„¸ì…˜ ìƒíƒœì— Thread IDì™€ File ID ì €ì¥
if "thread_id" not in st.session_state:
    # ì±—ë´‡ ì‹œì‘ ì‹œ ìƒˆë¡œìš´ Thread ìƒì„±
    try:
        thread = client.beta.threads.create()
        st.session_state.thread_id = thread.id
        st.session_state.file_ids = []
    except Exception as e:
        st.error(f"Thread ìƒì„± ì‹¤íŒ¨: {e}")
        st.stop()


# -------------------------------------------------------------
# 3. Streamlit UI ë° íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
# -------------------------------------------------------------
st.title("ğŸ’° ì—°ë§ì •ì‚° ì„œë¥˜ ë¶„ì„ ì±—ë´‡ (Assistant API)")

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


uploaded_file = st.file_uploader("ì—°ë§ì •ì‚° ì„œë¥˜(PDF, PNG, JPG)ë¥¼ ì—¬ê¸°ì— ì²¨ë¶€í•˜ì„¸ìš”.", type=["pdf", "png", "jpg", "jpeg"], key="tax_doc_uploader")


# -------------------------------------------------------------
# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° ë° Assistant Run ì‹¤í–‰
# -------------------------------------------------------------
if prompt := st.chat_input("ì„œë¥˜ ë¶„ì„ì„ ìš”ì²­í•˜ê±°ë‚˜ ì§ˆë¬¸í•˜ì„¸ìš”."):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # 2. íŒŒì¼ ì²˜ë¦¬ ë° Assistant File ê°ì²´ ìƒì„±
    file_ids_to_add = []
    if uploaded_file is not None:
        try:
            # íŒŒì¼ì„ Azure OpenAIì— ì—…ë¡œë“œí•˜ì—¬ File IDë¥¼ ë°›ìŒ
            with st.spinner(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {uploaded_file.name}"):
                file = client.files.create(
                    file=uploaded_file,
                    purpose="assistants" # íŒŒì¼ ê²€ìƒ‰ ëª©ì ìœ¼ë¡œ ì‚¬ìš©
                )
            file_ids_to_add.append(file.id)
            st.session_state.file_ids.append(file.id)
            st.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ. (File ID: {file.id})")
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

    # 3. Threadì— ë©”ì‹œì§€ ì¶”ê°€
    try:
        # ë©”ì‹œì§€ì— íŒŒì¼ IDë¥¼ ì—°ê²°í•˜ì—¬ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ë„ë¡ ì§€ì‹œ
        message = client.beta.threads.messages.create(
            thread_id=st.session_state.thread_id,
            role="user",
            content=prompt,
            file_ids=file_ids_to_add
        )
    except Exception as e:
        st.error(f"ë©”ì‹œì§€ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        st.stop()
    

    # 4. Run ì‹¤í–‰ ë° ê²°ê³¼ ëŒ€ê¸°
    with st.chat_message("assistant"):
        placeholder = st.empty()
        
        try:
            run = client.beta.threads.runs.create(
                thread_id=st.session_state.thread_id,
                assistant_id=ASSISTANT_ID
            )
        except Exception as e:
            placeholder.error(f"Assistant Run ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            st.stop()
            
        
        # Looping until the run completes (ë¹„ë™ê¸° ì²˜ë¦¬)
        with st.spinner("AIê°€ ì„œë¥˜ë¥¼ ë¶„ì„í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            while run.status in ['queued', 'in_progress', 'cancelling']:
                time.sleep(1)
                run = client.beta.threads.runs.retrieve(
                    thread_id=st.session_state.thread_id,
                    run_id=run.id
                )
        
        assistant_reply = ""
        
        if run.status == 'completed':
            messages = client.beta.threads.messages.list(
                thread_id=st.session_state.thread_id,
                order='desc', # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ê°€ì ¸ì˜´
                limit=1
            )
            # Assistantì˜ ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            assistant_reply = messages.data[0].content[0].text.value
            
        elif run.status == 'requires_action':
             assistant_reply = "Assistantê°€ í•¨ìˆ˜ í˜¸ì¶œì„ ìš”ì²­í–ˆì§€ë§Œ, ì´ ë²„ì „ì—ì„œëŠ” ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        else:
            assistant_reply = f"ì˜¤ë¥˜ ë°œìƒ ë˜ëŠ” Run ìƒíƒœ: {run.status}"

        # 5. AI ì‘ë‹µ í™”ë©´ì— ì¶œë ¥ ë° ì €ì¥
        placeholder.markdown(assistant_reply)
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
