import streamlit as st
import os
import json
import requests
from openai import AzureOpenAI
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone 
import warnings
import base64 

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì— AZURE_OAI_KEY, AZURE_OAI_ENDPOINT ì„¤ì • í•„ìˆ˜)
load_dotenv() 

# -------------------------------------------------------------
# ì„¤ì • ë° ë„êµ¬ ì •ì˜ (ìƒëµ) - ì´ ë¶€ë¶„ì€ ë¬¸ì œê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •í•©ë‹ˆë‹¤.
# -------------------------------------------------------------
deployment_name = "gpt-4o-mini"
# ... (get_tax_tip_for_category í•¨ìˆ˜, tools_definitions, available_functions ì •ì˜ ìƒëµ) ...

# -------------------------------------------------------------
# 3. Streamlit UI ë° ì±—ë´‡ ë¡œì§
# -------------------------------------------------------------

st.title("ğŸ’° ì—°ë§ì •ì‚° ê³µì œ íŒ ì±—ë´‡")

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# íŒŒì¼ ì—…ë¡œë”
uploaded_file = st.file_uploader("ì—°ë§ì •ì‚° ì„œë¥˜(PDF, PNG, JPG)ë¥¼ ì—¬ê¸°ì— ì²¨ë¶€í•˜ì„¸ìš”.", type=["pdf", "png", "jpg", "jpeg"], key="tax_doc_uploader")

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ì—°ë§ì •ì‚° ì ˆì„¸ ì½”ì¹˜'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìê°€ í•©ë²•ì ìœ¼ë¡œ ì„¸ì•¡ ê³µì œë‚˜ ì†Œë“ ê³µì œë¥¼ ìµœëŒ€í•œ ë§ì´ ë°›ì„ ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ íŒê³¼ ìš”ê±´ì„ ì•ˆë‚´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
1. ì—­í• : ...
2. ì„œë¥˜ ë¶„ì„: ...
3. ë„êµ¬ ì‚¬ìš©: ...
4. íƒœë„: ...
5. ì œí•œ: ..."""


# -------------------------------------------------------------
# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° API í˜¸ì¶œ (BadRequestError ë°©ì§€ ìµœì¢… ì½”ë“œ)
# -------------------------------------------------------------
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    
    # 1. í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (UI í‘œì‹œ ë° API ì „ì†¡ìš©)
    with st.chat_message("user"):
        st.markdown(prompt)
        
        # API ì „ì†¡ìš© ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±: í•­ìƒ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘
        current_api_user_content = []
        
        # íŒŒì¼ ì²¨ë¶€ ì²˜ë¦¬ ë° Base64 ì¸ì½”ë”©
        is_file_attached = False
        if uploaded_file is not None:
            try:
                file_bytes = uploaded_file.read()
                encoded_file = base64.b64encode(file_bytes).decode('utf-8')
                mime_type = uploaded_file.type 
                
                # íŒŒì¼ ë°ì´í„°ë¥¼ API ìš”ì²­ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                current_api_user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{encoded_file}",
                        "detail": "high"
                    }
                })
                st.info(f"ì²¨ë¶€ëœ íŒŒì¼({uploaded_file.name}, íƒ€ì…: {mime_type})ì„ ë¶„ì„ ìš”ì²­ì— í¬í•¨í–ˆìŠµë‹ˆë‹¤.")
                is_file_attached = True
                
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                
        # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ API ìš”ì²­ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        current_api_user_content.append({"type": "text", "text": prompt})
        
    # **ì˜¤ë¥˜ ë°©ì§€ í•µì‹¬ 1:** ì„¸ì…˜ ìƒíƒœì—ëŠ” ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ ë¬¸ìì—´ë§Œ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})


    # -------------------------------------------------------------------
    # 2. API ìš”ì²­ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    # -------------------------------------------------------------------
    with st.chat_message("assistant"):
        placeholder = st.empty()

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        messages_for_completion = [{"role": "system", "content": SYSTEM_PROMPT}]
        
        # **ì˜¤ë¥˜ ë°©ì§€ í•µì‹¬ 2:** ê¸°ì¡´ ì„¸ì…˜ ê¸°ë¡ ì¶”ê°€ (ì•ˆì „ í•„í„°ë§)
        safe_history = []
        for m in st.session_state.messages[:-1]:
            # contentê°€ ë¬¸ìì—´ì´ê³  ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ API Historyì— í¬í•¨
            if m.get("content") and isinstance(m["content"], str) and m["content"].strip():
                safe_history.append({
                    "role": m["role"],
                    "content": m["content"]
                })
        
        messages_for_completion.extend(safe_history)
        
        # í˜„ì¬ ì‚¬ìš©ìì˜ ìµœì¢… API ìš”ì²­ ë©”ì‹œì§€ ì¶”ê°€
        messages_for_completion.append({
            "role": "user",
            "content": current_api_user_content
        })


        # -------------------------------------------------------------------
        # 3. API í˜¸ì¶œ ë° ë„êµ¬ ì‚¬ìš© ë¡œì§ (Line 177ì´ ì—¬ê¸°ì„œ ì‹œì‘ë©ë‹ˆë‹¤.)
        # -------------------------------------------------------------------
        response = client.chat.completions.create( 
            model=deployment_name, 
            messages=messages_for_completion,
            tools=tools_definitions,
            tool_choice="auto",
        )

        response_message = response.choices[0].message
        assistant_reply = ""

        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš° (1ì°¨ í˜¸ì¶œ)
        if response_message.tool_calls:
            # 1ì°¨ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€ (API ì¬í˜¸ì¶œìš©)
            messages_for_completion.append(response_message)
            
            for tool_call in response_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)

                function_response = available_functions[function_name](**function_args)

                messages_for_completion.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                })

            # 2ì°¨ í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
            final_response = client.chat.completions.create(
                model=deployment_name,
                messages=messages_for_completion,
            )
            assistant_reply = final_response.choices[0].message.content

        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ê±°ë‚˜ 2ì°¨ í˜¸ì¶œ ê²°ê³¼ê°€ ë‚˜ì˜¨ ê²½ìš°
        else:
            assistant_reply = response_message.content

        # (4) AI ì‘ë‹µ í™”ë©´ì— ì¶œë ¥ ë° ì €ì¥
        placeholder.markdown(assistant_reply)
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})






