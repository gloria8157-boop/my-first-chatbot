import streamlit as st
import os
import json
import requests
from openai import AzureOpenAI
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone # ì‹œê°„ ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€
import warnings

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()



OPENWEATHER_API_KEY = "8538da5f00be6a0906782d7ea86c56aa"
deployment_name = "gpt-4o-mini" # ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ë°°í¬ëª…

def get_location_data(location):
    """OpenWeatherMap APIë¥¼ í†µí•´ ë‚ ì”¨ì™€ íƒ€ì„ì¡´ ì˜¤í”„ì…‹ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜"""
    if not OPENWEATHER_API_KEY:
        return None
    url = f"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={OPENWEATHER_API_KEY}&units=metric"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        else:
            # 404 ì˜¤ë¥˜ ë“±ì„ ëª¨ë¸ì—ê²Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬
            return json.dumps({"error": f"API Error: {response.status_code}"})
    except Exception as e:
        return json.dumps({"error": f"Request failed: {e}"})

def get_current_weather(location, unit="celsius"):
    """ì‹¤ì œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜"""
    data = get_location_data(location)
    if data and "error" not in data:
        temp_c = data["main"]["temp"]
        weather_desc = data["weather"][0]["description"]
        final_temp = temp_c
        if unit == "fahrenheit":
            final_temp = (temp_c * 9/5) + 32

        return json.dumps({
            "location": location,
            "temperature": round(final_temp, 1),
            "unit": unit,
            "description": weather_desc
        })
    return json.dumps({"location": location, "temperature": "unknown"})

def get_current_time(location):
    """ì‹¤ì œ APIì˜ Timezone offsetì„ ì´ìš©í•˜ì—¬ í˜„ì§€ ì‹œê°„ ê³„ì‚°"""
    data = get_location_data(location)
    if data and "error" not in data:
        timezone_offset = data["timezone"]
        utc_now = datetime.now(timezone.utc)
        local_time = utc_now + timedelta(seconds=timezone_offset)

        return json.dumps({
            "location": location,
            "current_time": local_time.strftime("%Y-%m-%d %I:%M %p")
        })
    return json.dumps({"location": location, "current_time": "unknown"})

tools_definitions = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "ì§€ì—­ì˜ í˜„ì¬ ë‚ ì”¨(ì˜¨ë„, ìƒíƒœ)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ë„ì‹œ ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "The city name, e.g. Seoul or Tokyo."},
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"], "description": "Temperature unit."},
                },
                "required": ["location"],
            },
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "ì§€ì—­ì˜ í˜„ì¬ í˜„ì§€ ì‹œê°„ì„ ì¡°íšŒí•©ë‹ˆë‹¤. ë„ì‹œ ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "The city name, e.g. Seoul or Tokyo."},
                },
                "required": ["location"],
            },
        }
    }
]

# ë„êµ¬ ì´ë¦„ê³¼ ì‹¤ì œ Python í•¨ìˆ˜ë¥¼ ë§¤í•‘
available_functions = {
    "get_current_weather": get_current_weather,
    "get_current_time": get_current_time
}

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# (ì‹¤ì œ ê°’ì€ .env íŒŒì¼ì´ë‚˜ ì—¬ê¸°ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”)
st.title("ğŸ¤– ì‹¤ì‹œê°„ ë‚ ì”¨ & ì‹œê°„ ì±—ë´‡")

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™” - ì´ê²Œ ì—†ìœ¼ë©´ ìƒˆë¡œê³ ì¹¨ ë•Œë§ˆë‹¤ ëŒ€í™”ê°€ ë‚ ì•„ê°‘ë‹ˆë‹¤!
if "messages" not in st.session_state:
    st.session_state.messages = []

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì•„ë‹˜, ë‹¨ìˆœ í˜¸ì¶œ ì˜ˆì‹œ)
    with st.chat_message("assistant"):
        # ì‘ë‹µ ì˜ì—­ Placeholder
        placeholder = st.empty()

        # Streamlit ì„¸ì…˜ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì‹œìŠ¤í…œ ì§€ì¹¨ í¬í•¨)
        messages_for_completion = [
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ]

        response = client.chat.completions.create(
                model=deployment_name, 
                messages=messages_for_completion,
                tools=tools_definitions,
                tool_choice="auto",
            )

        response_message = response.choices[0].message
        messages_for_completion.append(response_message)

        assistant_reply = ""

            # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°
        if response_message.tool_calls:

            for tool_call in response_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)

                # Python í•¨ìˆ˜ ì‹¤í–‰
                function_response = available_functions[function_name](**function_args)

                # ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€ (ì´ ê²°ê³¼ê°€ 2ì°¨ í˜¸ì¶œ ì‹œ ëª¨ë¸ì—ê²Œ ì „ë‹¬ë¨)
                messages_for_completion.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                })

            # 2ì°¨ í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
            final_response = client.chat.completions.create(
                model=deployment_name,
                messages=messages_for_completion,
            )
            assistant_reply = final_response.choices[0].message.content

        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ê±°ë‚˜ 2ì°¨ í˜¸ì¶œ ê²°ê³¼ê°€ ë‚˜ì˜¨ ê²½ìš°
        else:
            assistant_reply = response_message.content

        # (3) AI ì‘ë‹µ í™”ë©´ì— ì¶œë ¥ ë° ì €ì¥
        placeholder.markdown(assistant_reply)
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
